{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koll-ai/control-meme-api/blob/main/control_meme_api_temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Install dependencies\n",
        "\n",
        "!pip install \"git+https://github.com/takuma104/diffusers.git@controlnet\" # Diffusers in development version\n",
        "!pip install transformers accelerate safetensors xformers opencv-python\n",
        "!pip install --pre -U triton\n",
        "!pip install flask-cors\n",
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "id": "lAVHoRw4_w89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionControlNetPipeline, EulerAncestralDiscreteScheduler\n",
        "from diffusers.utils import load_image\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from flask import Flask\n",
        "from flask import request\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "from flask_cors import CORS\n",
        "\n",
        "import requests"
      ],
      "metadata": {
        "id": "O-_-FvpsU-9V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Load ControlNet pipeline\n",
        "\n",
        "model = \"takuma104/control_sd15_canny\" #@param [\"takuma104/control_sd15_mlsd\", \"takuma104/control_sd15_hed\", \"takuma104/control_sd15_seg\", \"takuma104/control_sd15_depth\", \"takuma104/control_sd15_scribble\", \"takuma104/control_sd15_normal\", \"takuma104/control_sd15_openpose\", \"takuma104/control_sd15_canny\"]\n",
        "\n",
        "#Common\n",
        "euler_scheduler = EulerAncestralDiscreteScheduler.from_config(model, subfolder=\"scheduler\")\n",
        "\n",
        "#Canny Edge model\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(model, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = euler_scheduler\n",
        "pipe.enable_xformers_memory_efficient_attention()\n"
      ],
      "metadata": {
        "id": "65XSa7JYAPra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "\n",
        "def create_hint(image, hint_type):\n",
        "  init_image = image.resize((512,512))\n",
        "  \n",
        "  if hint_type == 'canny':\n",
        "    controlnet_hint = Image.fromarray(cv.Canny(np.array(init_image), 100,200))\n",
        "  \n",
        "  controlnet_hint.save('last_hint.jpeg')\n",
        "\n",
        "  return controlnet_hint.convert('RGB')\n",
        "\n",
        "def generate_controlnet(prompt, hint, num_inference_steps, seed=None, negative_prompt=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Generate a meme variation\n",
        "    POST params: prompt:str, negative_prompt:str, controlnet_hint_url:str, num_inference_steps:int, seed:int\n",
        "    \"\"\"\n",
        "    \n",
        "    generator = torch.Generator(device=\"cuda\")\n",
        "\n",
        "    if seed:\n",
        "      generator.manual_seed(seed)\n",
        "\n",
        "    image = pipe(prompt=prompt, \n",
        "                negative_prompt=negative_prompt,\n",
        "                image=hint,\n",
        "                num_inference_steps=num_inference_steps, \n",
        "                generator=generator).images[0]\n",
        "    \n",
        "    with open('./last_meme.jpeg', 'w') as f:\n",
        "      image.save(f, format=\"JPEG\")\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "j4x8aCUCVIoB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "params = dict()\n",
        "\n",
        "API_URL = \"\"\n",
        "\n",
        "@app.route('/hello/')\n",
        "def hello():    \n",
        "    return \"hello\"\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def index():\n",
        "    global params\n",
        "\n",
        "    params = request.get_json()\n",
        "\n",
        "    meme_url = params['controlnet_hint_url']\n",
        "    image = Image.open(requests.get(meme_url, stream=True).raw)\n",
        "    hint = create_hint(image, 'canny')\n",
        "\n",
        "    last_image = generate_controlnet(hint=hint, **params)\n",
        "\n",
        "    buffered = BytesIO()\n",
        "    last_image.save(buffered, format=\"JPEG\")\n",
        "\n",
        "    return base64.b64encode(buffered.getvalue())\n",
        "\n",
        "\n",
        "@app.route('/save_last/')\n",
        "def save_last():\n",
        "    requests.post(f\"{API_URL}/api/meme/{params['uuid']}/variation/\",\n",
        "                  files=dict(\n",
        "                      file=open('./last.jpeg'),\n",
        "                      prompt=params[\"prompt\"],\n",
        "                      nb_steps=params[\"num_inference_steps\"]\n",
        "                      )\n",
        "                  )    \n",
        "    return \"ok\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  with open('output.txt', 'r') as f:\n",
        "      contents = f.read()\n",
        "      API_URL = contents.split(' ')[-1]\n",
        "      protocol = API_URL.split(':')[0]\n",
        "      url = API_URL.split('/')[-1]\n",
        "\n",
        "      print(API_URL)\n",
        "\n",
        "      print('\\n'*2)\n",
        "      print(f'Everything is ready! Click on the this link to be redirected to koll.ai. Don\\'t close this tab!')\n",
        "      print(f'https://meme.koll.ai?protocol={protocol}&url={url}')\n",
        "\n",
        "  app.run()"
      ],
      "metadata": {
        "id": "FXx-YzhUEtNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBD_TcdleddU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KGoIrKnedqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meme_url = \"https://storage.googleapis.com/control-meme-public/hidethepainharold.jpg\"\n",
        "\n",
        "image = Image.open(requests.get(meme_url, stream=True).raw)\n",
        "image\n",
        "\n",
        "# get controlnet hint image\n",
        "hint = create_hint(image, 'canny')\n",
        "hint\n",
        "\n",
        "params = {\"prompt\": \"Macron on the phone, french flags\",\n",
        "          \"hint\": hint,\n",
        "          \"num_inference_steps\": 50\n",
        "        }\n",
        "\n",
        "b64 = generate_controlnet(**params)\n",
        "b64"
      ],
      "metadata": {
        "id": "275yc0bKed1F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}