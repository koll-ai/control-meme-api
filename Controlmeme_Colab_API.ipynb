{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZxDDYUiEIsQz",
        "K3uds35nXcXs",
        "mpFq-Mje8ME8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koll-ai/control-meme-api/blob/main/Controlmeme_Colab_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install deps ( ~1 min)"
      ],
      "metadata": {
        "id": "ZxDDYUiEIsQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -Lo memfix.zip https://github.com/nolanaatama/sd-webui/raw/main/memfix.zip\n",
        "!unzip /content/memfix.zip\n",
        "!apt install -qq libunwind8-dev\n",
        "!dpkg -i *.deb\n",
        "%env LD_PRELOAD=libtcmalloc.so\n",
        "!rm *\n",
        "!pip install --upgrade fastapi==0.90.1\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "!git clone https://github.com/nolanaatama/sd-webui-tunnels /content/stable-diffusion-webui/extensions/sd-webui-tunnels\n",
        "!git clone https://github.com/Mikubill/sd-webui-controlnet /content/stable-diffusion-webui/extensions/sd-webui-controlnet\n",
        "!git clone https://github.com/fkunn1326/openpose-editor /content/stable-diffusion-webui/extensions/openpose-editor\n",
        "!git clone https://github.com/yfszzx/stable-diffusion-webui-images-browser /content/stable-diffusion-webui/extensions/stable-diffusion-webui-images-browser\n",
        "!git clone https://github.com/DominikDoom/a1111-sd-webui-tagcomplete /content/stable-diffusion-webui/extensions/a1111-sd-webui-tagcomplete\n",
        "# Model Code\n",
        "!curl -Lo /content/stable-diffusion-webui/models/Stable-diffusion/dreamshaper3.32bvcf.ckpt https://huggingface.co/Lykon/DreamShaper/resolve/main/Dreamshaper_3.32_baked_vae_clip_fix.ckpt\n",
        "# ControlNet\n",
        "!curl -Lo /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_canny.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_canny-fp16.safetensors\n",
        "# !curl -Lo /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_depth.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_depth-fp16.safetensors\n",
        "# !curl -Lo /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_hed-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_hed-fp16.safetensors\n",
        "# !curl -Lo /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_mlsd-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_mlsd-fp16.safetensors\n",
        "# !curl -Lo /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_normal-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_normal-fp16.safetensors\n",
        "# !curl -Lo /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_openpose-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors\n",
        "# !curl -Lo /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_scribble-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors\n",
        "# !curl -Lo /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_seg-fp16.safetensors https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_seg-fp16.safetensors\n",
        "import shutil\n",
        "shutil.rmtree('/content/stable-diffusion-webui/embeddings')\n",
        "%cd /content/stable-diffusion-webui\n",
        "!git checkout 0cc0ee1\n",
        "!git clone https://huggingface.co/nolanaatama/embeddings\n",
        "# Web UI tunnel (use cloudflare by default)\n",
        "# If cloudflare failed to start, we may try these options:\n",
        "# Change '--cloudflared' to '--remotemoe' on the COMMANDLINE_ARGS line above to use remotemoe tunnel\n",
        "# Change '--cloudflared' to '--localhostrun' to use localhost.run tunnel\n",
        "# Change '--cloudflared' to '--share' to use gradio tunnel\n",
        "!curl -Lo /content/stable-diffusion-webui/models/Lora/wanostyle_2.safetensors https://huggingface.co/nolanaatama/opwslora/resolve/main/onePieceWanoStyle_20.safetensors\n",
        "!curl -Lo /content/stable-diffusion-webui/models/Lora/last.pt https://huggingface.co/closertodeath/dpepmkmp/resolve/main/last.pt\n",
        "!curl -Lo /content/stable-diffusion-webui/models/Lora/anime_screencap_v2-000030.safetensors https://huggingface.co/nolanaatama/asslora/resolve/main/asslora.safetensors\n",
        "\n",
        "!npm i -g localtunnel\n",
        "!pip install flask\n",
        "!pip install flask_cors\n"
      ],
      "metadata": {
        "id": "IhA2QsWXFyYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from flask import Flask\n",
        "from flask import request, send_file\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "from flask_cors import CORS\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "from io import BytesIO\n",
        "import sys\n",
        "sys.path.append('/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts')\n",
        "sys.path.append('/content/stable-diffusion-webui/extensions/sd-webui-controlnet')\n",
        "import cv2\n",
        "from processor import canny, simple_scribble, hed, unload_hed, fake_scribble, mlsd, unload_mlsd, midas, midas_normal, unload_midas, leres, unload_leres, openpose, openpose_hand, unload_openpose, uniformer, unload_uniformer, pidinet, unload_pidinet\n",
        "import imutils\n",
        "from PIL import Image\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "from base64 import b64encode"
      ],
      "metadata": {
        "id": "LHRziBmApROD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmjTkwCZanRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "\n",
        "def cv_to_b64(cv_image):\n",
        "    _, im_arr = cv2.imencode('.jpg', cv_image)  # im_arr: image in Numpy one-dim array format.\n",
        "    im_bytes = im_arr.tobytes()\n",
        "    im_b64 = base64.b64encode(im_bytes)\n",
        "    return im_b64\n",
        "\n",
        "def adjust_size(width, height):\n",
        "    ratio = width/height\n",
        "    if(ratio > 1):\n",
        "        width = 512\n",
        "        round_width = width\n",
        "\n",
        "        height = round(512 * 1/ratio)\n",
        "        round_height = ((height + 32) // 64) * 64\n",
        "        round_height = int(max(round_height, 64))\n",
        "    else:\n",
        "        height = 512\n",
        "        round_height = height\n",
        "\n",
        "        width = round(512 * ratio) \n",
        "        round_width = ((width + 32) // 64) * 64\n",
        "        round_width = int(max(round_width, 64))\n",
        "\n",
        "    return round_width, round_height\n",
        "\n",
        "class controlnetRequest():\n",
        "    def __init__(self, hint, **kwargs ):\n",
        "        self.url = \"http://localhost:7860/controlnet/txt2img\"\n",
        "\n",
        "        w, h = adjust_size(hint.shape[1], hint.shape[0])\n",
        "\n",
        "        #resized = cv2.resize(hint, (w, h))\n",
        "        hint_b64 = cv_to_b64(hint)\n",
        "        hint_b64 = hint_b64.decode(\"utf-8\")\n",
        "\n",
        "        # get the parameters from the kwargs or use default value\n",
        "        self.body = {\n",
        "            \"prompt\": kwargs.get(\"prompt\", \"\"),\n",
        "            \"negative_prompt\": kwargs.get(\"negative_prompt\", \"\"),\n",
        "            \"seed\": kwargs.get(\"seed\", -1),\n",
        "            \"subseed\": kwargs.get(\"subseed\", -1),\n",
        "            \"subseed_strength\": kwargs.get(\"subseed_strength\", 0),\n",
        "            \"batch_size\": kwargs.get(\"batch_size\", 1),\n",
        "            \"n_iter\": kwargs.get(\"n_iter\", 1),\n",
        "            \"steps\": kwargs.get(\"steps\", 30),\n",
        "            \"cfg_scale\": kwargs.get(\"cfg_scale\", 7),\n",
        "            \"width\": w,\n",
        "            \"height\": h,\n",
        "            \"restore_faces\": kwargs.get(\"restore_faces\", True),\n",
        "            \"eta\": kwargs.get(\"eta\", 0),\n",
        "            \"sampler_index\": kwargs.get(\"sampler_index\", \"Euler a\"),\n",
        "            \"controlnet_input_image\": [hint_b64],\n",
        "            \"controlnet_module\": kwargs.get(\"controlnet_module\", \"none\"),\n",
        "            \"controlnet_model\": kwargs.get(\"controlnet_model\", \"control_canny [e3fe7712]\"),\n",
        "            \"controlnet_guidance\": kwargs.get(\"controlnet_guidance\", 1.0)\n",
        "        }\n",
        "            \n",
        "\n",
        "    def sendRequest(self):\n",
        "        r = requests.post(self.url, json=self.body)\n",
        "        return r.json()\n",
        "\n",
        "\n",
        "def create_hint(init_image, processor_model, controlnet_processor_res=512, thresholdA=None, thresholdB=None):\n",
        "    \"\"\" Create a hint image from the initial image and the processor model\n",
        "    Args:\n",
        "        init_image: np array of the initial image \n",
        "        processor_model: the processor model, one of the following: \n",
        "            - canny\n",
        "            - simple_scribble\n",
        "            - hed\n",
        "            - fake_scribble\n",
        "            - mlsd\n",
        "            - midas\n",
        "            - midas_normal\n",
        "            - leres\n",
        "            - openpose\n",
        "            - openpose_hand\n",
        "            - uniformer\n",
        "        thresholdA: the threshold A\n",
        "        thresholdB: the threshold B\n",
        "    \"\"\"\n",
        "    if processor_model == \"canny\":\n",
        "        return canny(init_image, controlnet_processor_res, thresholdA, thresholdB)\n",
        "    elif processor_model == \"hed\":\n",
        "        return hed(init_image, controlnet_processor_res)\n",
        "    elif processor_model == \"mlsd\":\n",
        "        return mlsd(init_image, controlnet_processor_res, thresholdA, thresholdB)\n",
        "    elif processor_model == \"depth\":\n",
        "        return midas(init_image, controlnet_processor_res, np.pi * 2.0)\n",
        "    elif processor_model == \"normal_map\":\n",
        "        return midas_normal(init_image, controlnet_processor_res, np.pi * 2.0, thresholdA)\n",
        "    elif processor_model == \"depth_leres\":\n",
        "        return leres(init_image, controlnet_processor_res, np.pi * 2.0, thresholdA, thresholdB)\n",
        "    elif processor_model == \"openpose\":\n",
        "        return openpose(init_image, controlnet_processor_res, False)\n",
        "    elif processor_model == \"openpose_hand\":\n",
        "        return openpose_hand(init_image, controlnet_processor_res, True)\n",
        "    elif processor_model == \"fake_scribble\":\n",
        "        return fake_scribble(init_image, controlnet_processor_res)\n",
        "    elif processor_model == \"segmentation\":\n",
        "        return uniformer(init_image, controlnet_processor_res)\n",
        "    elif processor_model == \"pidinet\":\n",
        "        return pidinet(init_image, controlnet_processor_res)\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "    \n",
        "\n",
        "def generate_controlnet(hint, **kwargs):\n",
        "    \"\"\" Generate the controlnet meme by making a request to local api\n",
        "    Args:\n",
        "        hint: the hint image b64 encoded\n",
        "        kwargs: the parameters of the controlnet\n",
        "            - nb_steps: the number of steps\n",
        "            - prompt: the prompt\n",
        "            - guess_mode: false if we want to use the prompt, true if we want to use the guess\n",
        "    Returns:\n",
        "        List of images generated by controlnet\n",
        "    \"\"\"\n",
        "    \n",
        "    req = controlnetRequest(hint, **kwargs)\n",
        "    resp = req.sendRequest()\n",
        "    \n",
        "    return resp['images']\n",
        "    "
      ],
      "metadata": {
        "id": "fVYftJmnql7t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file /content/make_video.sh\n",
        "# https://gist.github.com/anguyen8/d0630b6aef6c1cd79b9a1341e88a573e\n",
        "\n",
        "\n",
        "#!/bin/bash\n",
        "\n",
        "# Anh Nguyen <anh.ng8@gmail.com>\n",
        "# 2016-04-30\n",
        "# MIT License\n",
        "\n",
        "# This script takes in same-size images from a folder and make a crossfade video from the images using ffmpeg.\n",
        "# Make sure you have ffmpeg installed before running.\n",
        "\n",
        "# The output command looks something like the below, but for as many images as you have in the folder.\n",
        "# See the answer by LordNeckbeard at:\n",
        "# http://superuser.com/questions/833232/create-video-with-5-images-with-fadein-out-effect-in-ffmpeg/1071748#1071748\n",
        "#\n",
        "#\n",
        "# ffmpeg \\\n",
        "# -loop 1 -t 1 -i 001.png \\\n",
        "# -loop 1 -t 1 -i 002.png \\\n",
        "# -loop 1 -t 1 -i 003.png \\\n",
        "# -loop 1 -t 1 -i 004.png \\\n",
        "# -loop 1 -t 1 -i 005.png \\\n",
        "# -filter_complex \\\n",
        "# \"[1:v][0:v]blend=all_expr='A*(if(gte(T,0.5),1,T/0.5))+B*(1-(if(gte(T,0.5),1,T/0.5)))'[b1v]; \\\n",
        "# [2:v][1:v]blend=all_expr='A*(if(gte(T,0.5),1,T/0.5))+B*(1-(if(gte(T,0.5),1,T/0.5)))'[b2v]; \\\n",
        "# [3:v][2:v]blend=all_expr='A*(if(gte(T,0.5),1,T/0.5))+B*(1-(if(gte(T,0.5),1,T/0.5)))'[b3v]; \\\n",
        "# [4:v][3:v]blend=all_expr='A*(if(gte(T,0.5),1,T/0.5))+B*(1-(if(gte(T,0.5),1,T/0.5)))'[b4v]; \\\n",
        "# [0:v][b1v][1:v][b2v][2:v][b3v][3:v][b4v][4:v]concat=n=9:v=1:a=0,format=yuv420p[v]\" -map \"[v]\" out.mp4\n",
        "\n",
        "#----------------------------------------------------------------\n",
        "# SETTINGS\n",
        "input_dir=\"/content/video\"  # Replace this by a path to your folder /path/to/your/folder\n",
        "n_files=3                        # Replace this by a number of images\n",
        "files=`ls ${input_dir}/*.jpeg | head -${n_files}`  # Change the file type to the correct type of your images\n",
        "output_file=\"/content/video.mp4\"           # Name of output video\n",
        "crossfade=0.9                     # Crossfade duration between two images\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "# Making an ffmpeg script...\n",
        "input=\"\"\n",
        "filters=\"\"\n",
        "output=\"[0:v]\"\n",
        "\n",
        "i=0\n",
        "\n",
        "for f in ${files}; do\n",
        "  input+=\" -loop 1 -t 1 -i $f\"\n",
        "\n",
        "  next=$((i+1))\n",
        "  if [ \"${i}\" -ne \"$((n_files-1))\" ]; then\n",
        "    filters+=\" [${next}:v][${i}:v]blend=all_expr='A*(if(gte(T,${crossfade}),1,T/${crossfade}))+B*(1-(if(gte(T,${crossfade}),1,T/${crossfade})))'[b${next}v];\"\n",
        "  fi\n",
        "\n",
        "  if [ \"${i}\" -gt \"0\" ]; then\n",
        "    output+=\"[b${i}v][${i}:v]\"\n",
        "  fi\n",
        "\n",
        "  i=$((i+1))\n",
        "done\n",
        "\n",
        "output+=\"concat=n=$((i * 2 - 1)):v=1:a=0,format=yuv420p[v]\\\" -map \\\"[v]\\\" ${output_file}\"\n",
        "\n",
        "script=\"ffmpeg ${input} -filter_complex \\\"${filters} ${output}\"\n",
        "\n",
        "echo ${script}\n",
        "\n",
        "# Run it\n",
        "eval \"${script}\""
      ],
      "metadata": {
        "id": "NbvrPm2wULTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4c6b39-c020-4469-ea5b-3c568c6ef32a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/make_video.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_ffmep(img1_url, img2_url):\n",
        "  !mkdir -p /content/video\n",
        "\n",
        "  !wget -O /content/video/im1.jpeg {img1_url}\n",
        "  !wget -O /content/video/im2.jpeg {img2_url}\n",
        "  !cp /content/video/im1.jpeg /content/video/im3.jpeg\n",
        "  !yes | bash /content/make_video.sh\n",
        "\n",
        "  return '/content/video.mp4'\n",
        "\n"
      ],
      "metadata": {
        "id": "fsjPVDvQUMi9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this cell and click on the outputed meme.koll.ai?gpuURL=XXX to be redirected to the website or copy https://XXX in the colabsessionlink textfield. \n",
        "#Wait for sd-webui API to be started before making generation, logs are in /content/output_webui.txt ( ~3 min)\n",
        "(ready when 127.0.0.1 url are displayed at the end of the file)"
      ],
      "metadata": {
        "id": "9N7rFTtM7dVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "# run localtunnel\n",
        "with open('/content/output_tunnel.txt', 'w') as f:\n",
        "    proc = subprocess.Popen(['lt', '--port', '5000'], stdout=f)\n",
        "\n",
        "\n",
        "\n",
        "os.environ['COMMANDLINE_ARGS'] = \"--api --allow-code\t--enable-insecure-extension-access\t--disable-safe-unpickle --no-half-vae --xformers --reinstall-xformers --enable-insecure-extension- --gradio-queue\" \n",
        "os.environ['REQS_FILE'] = \"requirements.txt\"\n",
        "# del os.environ['REQS_FILE']\n",
        "\n",
        "with open('/content/output_webui.txt', 'w') as f:\n",
        "    proc_automatic = subprocess.Popen(['python', '-u', 'launch.py'], stdout=f, stderr=f)\n",
        "\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "params = dict()\n",
        "\n",
        "API_URL  = \"\"\n",
        "BACK_URL = \"https://controle-meme-back-n7bkntouja-uc.a.run.app\"\n",
        "\n",
        "\n",
        "#Route to generate the hint according to processor, thresholdA and thresholdB\n",
        "@app.route('/hint/', methods=['POST'])\n",
        "def hint():\n",
        "    params = request.get_json()\n",
        "    meme_url = params['controlnet_basememe_url']\n",
        "    processor_model = params['controlnet_module']\n",
        "    thresholdA = params['controlnet_threshold_a']\n",
        "    thresholdB = params['controlnet_threshold_b']\n",
        "    \n",
        "    # read the image from the url to cv2\n",
        "    base_meme = imutils.url_to_image(meme_url)    \n",
        "    hint = create_hint(base_meme, processor_model, thresholdA=thresholdA, thresholdB = thresholdB)\n",
        "    hint = hint[0]\n",
        "    \n",
        "    im_b64 = cv_to_b64(hint)\n",
        "    \n",
        "    return im_b64\n",
        "\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def index():\n",
        "    global params\n",
        "\n",
        "    params = request.get_json()\n",
        "    meme_url = params['controlnet_basememe_url']\n",
        "    processor_module = params['controlnet_module']\n",
        "    thresholdA = params['controlnet_threshold_a']\n",
        "    thresholdB = params['controlnet_threshold_b']\n",
        "        \n",
        "    # read the image from the url to cv2\n",
        "    base_meme = imutils.url_to_image(meme_url)    \n",
        "    hint = create_hint(base_meme, processor_module, thresholdA=thresholdA, thresholdB = thresholdB)\n",
        "    hint = hint[0]\n",
        "\n",
        "    # todo: send request to sdwebui api to get the generated image\n",
        "    try: \n",
        "        last_image = generate_controlnet(hint, **params)\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return \"Automatic api subprocess is not fully started yet, please try again in a minute\", 500\n",
        "      \n",
        "    last_image_b64 = last_image[0]\n",
        "    \n",
        "    # with open('./last_meme.jpeg', 'w') as f:\n",
        "    #   Image.open(BytesIO(base64.b64decode(last_image))).save(f, format=\"JPEG\")\n",
        "    # with open(\"./last_meme.jpeg\", \"wb\") as f:\n",
        "    #    f.write(last_image_b64)\n",
        "\n",
        "\n",
        "    decoded_data = base64.b64decode(last_image_b64)\n",
        "    np_data = np.fromstring(decoded_data,np.uint8)\n",
        "    img = cv2.imdecode(np_data,cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    cv2.imwrite('./last_meme.jpeg', img)\n",
        "\n",
        "\n",
        "\n",
        "    return last_image_b64\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/save_last/')\n",
        "def save_last():\n",
        "    global params\n",
        "\n",
        "    # last_image = Image.open('./last_meme.jpeg')\n",
        "    # buffered = BytesIO()\n",
        "    # last_image.save(buffered, format=\"JPEG\")\n",
        "    # img_str = base64.b64encode(buffered.getvalue())\n",
        "\n",
        "    last_image = cv2.imread('./last_meme.jpeg')\n",
        "    img_str = cv_to_b64(last_image)\n",
        "\n",
        "    data = dict(\n",
        "        memeID = params['uuid'],\n",
        "        imageb64=img_str.decode(\"utf-8\"),\n",
        "        prompt=params.get('prompt', 'no prompt'),\n",
        "        nb_steps=params.get('nb_steps', 'no data'),\n",
        "        parent_url = params.get('parent_url')\n",
        "    )\n",
        "    url = f'{BACK_URL}/api/save_variation/'\n",
        "    requests.post(url, json = data)\n",
        "\n",
        "    return \"ok\"\n",
        "\n",
        "\n",
        "@app.route('/generate_video/', methods=['POST'])\n",
        "def generate_video():\n",
        "    params = request.get_json()\n",
        "    \n",
        "    parent_url = params['parent_url']\n",
        "    variation_url = params['variation_url']\n",
        "\n",
        "    path_video = generate_video_ffmep(parent_url, variation_url)\n",
        "\n",
        "    return send_file(path_video)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/hello/')\n",
        "def hello():    \n",
        "    return \"hello\"\n",
        "\n",
        "# todo: add route to check if automatic api is started\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  with open('/content/output_tunnel.txt', 'r') as f:\n",
        "      contents = f.read()\n",
        "      API_URL = contents.split(' ')[-1]\n",
        "      protocol = API_URL.split(':')[0]\n",
        "      url = API_URL.split('/')[-1]\n",
        "\n",
        "      print(\"Backend URL:\", API_URL)\n",
        "\n",
        "      print('\\n'*2)\n",
        "      print(f'Everything is ready! Click on the this link to be redirected to koll.ai. Don\\'t close this tab!')\n",
        "      print(f'>>>>  https://meme.koll.ai?gpuURL={url}  <<<<')\n",
        "\n",
        "  app.run()"
      ],
      "metadata": {
        "id": "_1Pj06M7u2Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57NvVnl7lKpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests (ignore)"
      ],
      "metadata": {
        "id": "mpFq-Mje8ME8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meme_url = \"https://storage.googleapis.com/control-meme-public/gigachad.jpg\"\n",
        "\n",
        "image = Image.open(requests.get(meme_url, stream=True).raw)\n",
        "image\n",
        "\n",
        "#get controlnet hint image\n",
        "hint = create_hint(image, 'canny')\n",
        "hint\n",
        "\n",
        "params = {\"prompt\": \"Gigachad Thanos\",\n",
        "          \"hint\": hint,\n",
        "          \"num_inference_steps\": 30,\n",
        "          \"seed\": -1\n",
        "        }\n",
        "\n",
        "b64 = generate_controlnet(**params)\n",
        "b64"
      ],
      "metadata": {
        "id": "UuKH3Mq9rCi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "meme_url = \"https://storage.googleapis.com/control-meme-public/Salt-Bae-001.jpg\"\n",
        "processor_module = \"canny\"\n",
        "thresholdA = 40\n",
        "thresholdB = 120\n",
        "\n",
        "# read the image from the url to cv2\n",
        "base_meme = imutils.url_to_image(meme_url)    \n",
        "hint = create_hint(base_meme, processor_module, thresholdA=thresholdA, thresholdB = thresholdB)\n",
        "hint = Image.fromarray(hint)\n",
        "\n",
        "# convert the hint to bytes\n",
        "buffered = BytesIO()\n",
        "hint.save(buffered, format=\"JPEG\")\n",
        "\n",
        "# encode the bytes to base64\n",
        "hint_b64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "# todo: send request to sdwebui api to get the generated image\n",
        "last_image = generate_controlnet(hint_b64, **params)\n",
        "last_image = last_image[0]"
      ],
      "metadata": {
        "id": "t6GlrnOr4xoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vXg4LOCt6Vm5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}