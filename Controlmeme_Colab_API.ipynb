{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koll-ai/control-meme-api/blob/main/Controlmeme_Colab_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUXA3mBI6X7t"
      },
      "source": [
        "#How to use ControlMeme generation backend\n",
        "\n",
        "1. Run all cells until you see a meme.koll.ai link at the bottom of the page (this can take a while)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/koll-ai/control-meme-api/main/images/run_all.png\"  height=\"70\">\n",
        "\n",
        "2. Click the link to start creating new memes !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxDDYUiEIsQz"
      },
      "source": [
        "#1. Install dependencies ( ~2-3 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_AUTOMATIC1111.ipynb"
      ],
      "metadata": {
        "id": "op10zuhyEx3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install/Update AUTOMATIC1111 repo\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import time\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/\"):\n",
        "  print('\u001b[1;31mGdrive not connected, using colab storage ...')\n",
        "  time.sleep(4)\n",
        "  !mkdir -p /content/gdrive/MyDrive/\n",
        "with capture.capture_output() as cap:\n",
        "  def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "  fgitclone = \"git clone --depth 1\"\n",
        "  %mkdir -p /content/gdrive/MyDrive/sd\n",
        "  %cd /content/gdrive/MyDrive/sd\n",
        "  !$fgitclone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "  !mkdir -p /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/huggingface\n",
        "  !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/huggingface /root/.cache/\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  !git reset --hard\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "print('\u001b[1;32m')\n",
        "!git pull\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ],
      "metadata": {
        "id": "xul34RbpE3Bf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Requirements\n",
        "\n",
        "print('\u001b[1;32mInstalling requirements...')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/ \n",
        "  !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/A1111.txt\n",
        "  !dpkg -i *.deb\n",
        "  if not os.path.exists('/content/gdrive/MyDrive/sd/stablediffusion'):\n",
        "    !tar -C / --zstd -xf sd.tar.zst \n",
        "  !tar -C / --zstd -xf gcolab.tar.zst\n",
        "  !rm *.deb | rm *.zst | rm *.txt\n",
        "  %env LD_PRELOAD=libtcmalloc.so\n",
        "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "  !npm install -g localtunnel\n",
        "\n",
        "  !pip install flask flask_cors\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ],
      "metadata": {
        "id": "8YrGoIQIE2_K",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Model Download/Load\n",
        "Model_Version = \"1.5\" #@param [ \"1.5\", \"v1.5 Inpainting \", \"V2.1-512px\", \"V2.1-768px\"]\n",
        "\n",
        "Redownload_the_original_model = False #@param {type:\"boolean\"}\n",
        "\n",
        "def rmv():\n",
        "  !wget -q -O /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/README.md\n",
        "  !mv /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/trashfile.f\n",
        "  time.sleep(2)\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/trashfile.f\n",
        "  clear_output()\n",
        "\n",
        "if Redownload_the_original_model:\n",
        "  with capture.capture_output() as cap:\n",
        "    rmv()\n",
        "\n",
        "#@markdown Or\n",
        "Path_to_MODEL = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Insert the full path of your trained model or to a folder containing multiple models.\n",
        "\n",
        "#@markdown Or\n",
        "MODEL_LINK = \"https://huggingface.co/Lykon/DreamShaper/resolve/main/Dreamshaper_3.32_baked_vae_clip_fix.ckpt\" #@param {type:\"string\"}\n",
        "safetensors = False #@param {type:\"boolean\"}\n",
        "Use_temp_storage = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "def newmdl():\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      !$fgitclone --branch fp16 \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "      if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        !wget -q -O stable-diffusion-v1-5/vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n",
        "        !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "        !sed -i '201s@.*@    model_path = \"/content/stable-diffusion-v1-5\"@' /content/convertosd.py\n",
        "        !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt\"@' /content/convertosd.py\n",
        "        clear_output()       \n",
        "        !python /content/convertosd.py\n",
        "        !rm /content/convertosd.py\n",
        "        if os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "          model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "          clear_output()\n",
        "          inf('\\u2714 Done','success', '50px')\n",
        "        else:\n",
        "          inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "      else:\n",
        "        inf('\\u2718 Something went wrong','danger', \"200px\")\n",
        "\n",
        "    else:\n",
        "      model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists, check the box \"Redownload_the_original_model\" to redownload/download the V1.5','primary', '700px')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      !rm -r /content/stable-diffusion-v1-5\n",
        "\n",
        "    return model\n",
        "\n",
        "def V2():\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !mkdir \"/content/stable-diffusion-V2\"\n",
        "      %cd \"/content/stable-diffusion-V2\"\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      if Model_Version == \"V2.1-768px\":\n",
        "        !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "      elif Model_Version == \"V2.1-512px\":\n",
        "        !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
        "      !git config core.sparsecheckout true\n",
        "      !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "      !git pull origin fp16\n",
        "      %cd /content\n",
        "      !wget -O convertosdv2.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosdv2.py\n",
        "      clear_output()\n",
        "      !python /content/convertosdv2.py --fp16 /content/stable-diffusion-V2 /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt\n",
        "      !rm /content/convertosdv2.py\n",
        "      if os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "        model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "        clear_output()\n",
        "        inf('\\u2714 Done','success', '50px')\n",
        "      else:\n",
        "        inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "\n",
        "    else:\n",
        "      model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists, check the box \"Redownload_the_original_model\" to redownload/download the V2','primary', '700px')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "      !rm -r /content/convertosdv2.py\n",
        "    if os.path.exists('/content/stable-diffusion-V2'):\n",
        "      !rm -r /content/stable-diffusion-V2\n",
        "\n",
        "    return model\n",
        "\n",
        "def inpmdl():\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'):\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      !$fgitclone --branch fp16 \"https://huggingface.co/runwayml/stable-diffusion-inpainting\"\n",
        "      if os.path.exists('/content/stable-diffusion-inpainting'):\n",
        "        !$fgitclone \"https://huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "        !rm -r /content/stable-diffusion-inpainting/vae\n",
        "        !mv /content/sd-vae-ft-mse /content/stable-diffusion-inpainting/vae        \n",
        "        !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "        !sed -i '201s@.*@    model_path = \"/content/stable-diffusion-inpainting\"@' /content/convertosd.py\n",
        "        !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5-inpainting.ckpt\"@' /content/convertosd.py\n",
        "        clear_output()       \n",
        "        !python /content/convertosd.py\n",
        "        !rm /content/convertosd.py\n",
        "        if os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'):\n",
        "          model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "          clear_output()\n",
        "          inf('\\u2714 Done','success', '50px')\n",
        "        else:\n",
        "          inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "      else:\n",
        "        inf('\\u2718 Something went wrong','danger', \"200px\")\n",
        "\n",
        "\n",
        "    else:\n",
        "      model='/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "      clear_output()\n",
        "      inf('\\u2714 inpainting model already exists','primary', '250px')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-inpainting'):\n",
        "      !rm -r /content/stable-diffusion-inpainting\n",
        "\n",
        "    return model\n",
        "\n",
        "if (Path_to_MODEL !=''):\n",
        "  if os.path.exists(str(Path_to_MODEL)):\n",
        "    inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  else:\n",
        "      while not os.path.exists(str(Path_to_MODEL)):\n",
        "        inf('\\u2718 Wrong path, use the colab file explorer to copy the path : ','danger', \"400px\")\n",
        "        Path_to_MODEL=input()\n",
        "      if os.path.exists(str(Path_to_MODEL)):\n",
        "        inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  model=Path_to_MODEL\n",
        "\n",
        "elif MODEL_LINK != \"\":\n",
        "  gdrv=\"/content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "  tmp=\"/content\"\n",
        "  pth=tmp if Use_temp_storage else gdrv\n",
        "  %cd $pth\n",
        "  clear_output()\n",
        "  if not safetensors:\n",
        "    modelname=\"model.ckpt\"\n",
        "  else:\n",
        "    modelname=\"model.safetensors\"\n",
        "  !gdown --fuzzy -O $modelname $MODEL_LINK\n",
        "  if os.path.exists(f'{pth}/{modelname}') and os.path.getsize(f'{pth}/{modelname}') > 1810671599:    \n",
        "      model=f'{pth}/{modelname}'\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model downloaded, using the trained model.','success', '350px')\n",
        "  else:\n",
        "    if Use_temp_storage:\n",
        "      !rm $pth/$modelname\n",
        "    else:\n",
        "      rmv()\n",
        "    inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "\n",
        "elif Model_Version==\"1.5\":\n",
        "  model=newmdl()\n",
        "\n",
        "elif Model_Version==\"V2.1-512px\" or Model_Version==\"V2.1-768px\":\n",
        "  model=V2()\n",
        "\n",
        "else:\n",
        "   model=inpmdl()"
      ],
      "metadata": {
        "id": "TBN34HDoE28R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ControlNet\n",
        "from torch.hub import download_url_to_file\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "Model = \"All\" #@param [ \"All\", \"Canny\", \"Depth\", \"HED\", \"MLSD\", \"Normal\", \"OpenPose\", \"Scribble\", \"Seg\", \"T2iadapter_Models\"]\n",
        "\n",
        "#@markdown - Download/update ControlNet extension and its models.\n",
        "\n",
        "def download(url, model_dir):\n",
        "\n",
        "    filename = os.path.basename(urlparse(url).path)\n",
        "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
        "    if not os.path.exists(pth):\n",
        "        print('Downloading: '+os.path.basename(url))\n",
        "        download_url_to_file(url, pth, hash_prefix=None, progress=True)\n",
        "    else:\n",
        "      print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
        "\n",
        "Canny='https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_canny-fp16.safetensors'\n",
        "Depth='https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_depth-fp16.safetensors'\n",
        "HED='https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_hed-fp16.safetensors'\n",
        "MLSD='https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_mlsd-fp16.safetensors'\n",
        "Normal='https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_normal-fp16.safetensors'\n",
        "OpenPose='https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors'\n",
        "Scribble='https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors'\n",
        "Seg='https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_seg-fp16.safetensors'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions\n",
        "  if not os.path.exists(\"sd-webui-controlnet\"):\n",
        "    !git clone https://github.com/Mikubill/sd-webui-controlnet.git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd sd-webui-controlnet\n",
        "    !git pull\n",
        "    %cd /content\n",
        "\n",
        "!cp /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/*.yaml /content/gdrive/MyDrive/sd/stable-diffusion-webui/models\n",
        "mdldir=\"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models\"\n",
        "\n",
        "!wget -q -O CN_models.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models.txt\n",
        "with open(\"CN_models.txt\", 'r') as f:\n",
        "  mdllnk = f.read().splitlines()\n",
        "!rm CN_models.txt\n",
        "\n",
        "if Model == \"All\": \n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif Model == \"T2iadapter_Models\":\n",
        "  mdllnk=list(filter(lambda x: 't2i' in x, mdllnk))\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')"
      ],
      "metadata": {
        "id": "qXR5fT7QE23F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Start Stable-Diffusion\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "Use_localtunnel = False\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/\n",
        "  !wget -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
        "  !wget -O extras.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/extras.py\n",
        "  !wget -O sd_models.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.9/dist-packages/gradio/blocks.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "\n",
        "  !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_models.py\n",
        "  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/extras.py\n",
        "\n",
        "share=''\n",
        "if not Use_localtunnel:\n",
        "  share='--share'\n",
        "\n",
        "else:\n",
        "  with capture.capture_output() as cap:\n",
        "    share=''\n",
        "    %cd /content\n",
        "    !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "    time.sleep(2)\n",
        "    !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "    time.sleep(2)\n",
        "    srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "    for line in fileinput.input('/usr/local/lib/python3.9/dist-packages/gradio/blocks.py', inplace=True):\n",
        "      if line.strip().startswith('self.server_name ='):\n",
        "          line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "      if line.strip().startswith('self.protocol = \"https\"'):\n",
        "          line = '            self.protocol = \"https\"\\n'\n",
        "      if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "          line = ''\n",
        "      if line.strip().startswith('else \"http\"'):\n",
        "          line = ''\n",
        "      sys.stdout.write(line)\n",
        "            \n",
        "    !rm /content/srv.txt /content/srvr.txt\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "\n",
        "try:\n",
        "  model\n",
        "  if os.path.isfile(model):\n",
        "    !nohup python -u /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --nowebui --no-hashing\t--api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt \"$model\" --xformers --disable-console-progressbars > /content/output_webui.txt &\n",
        "  else:\n",
        "    !nohup python -u /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --nowebui --no-hashing --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt-dir \"$model\" --xformers --disable-console-progressbars > /content/output_webui.txt &\n",
        "except:\n",
        "   !nohup python -u /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --nowebui --no-hashing --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --xformers --disable-console-progressbars > /content/output_webui.txt &"
      ],
      "metadata": {
        "id": "GOVc1jCtE2vM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LHRziBmApROD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Js8ekwbLJl_h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fVYftJmnql7t",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # Define Helper function\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from flask import Flask\n",
        "from flask import request, send_file\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "from flask_cors import CORS\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "from io import BytesIO\n",
        "import sys\n",
        "import cv2\n",
        "import imutils\n",
        "from PIL import Image\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "from base64 import b64encode\n",
        "import logging\n",
        "import requests\n",
        "import base64\n",
        "import cv2\n",
        "import sys\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def cv_to_b64(cv_image):\n",
        "    # im_arr: image in Numpy one-dim array format.\n",
        "    _, im_arr = cv2.imencode('.jpg', cv_image)\n",
        "    im_bytes = im_arr.tobytes()\n",
        "    im_b64 = base64.b64encode(im_bytes)\n",
        "    return im_b64\n",
        "\n",
        "\n",
        "def adjust_size(width, height):\n",
        "    ratio = width/height\n",
        "    if (ratio > 1):\n",
        "        width = 512\n",
        "        round_width = width\n",
        "\n",
        "        height = round(512 * 1/ratio)\n",
        "        round_height = ((height + 32) // 64) * 64\n",
        "        round_height = int(max(round_height, 64))\n",
        "    else:\n",
        "        height = 512\n",
        "        round_height = height\n",
        "\n",
        "        width = round(512 * ratio)\n",
        "        round_width = ((width + 32) // 64) * 64\n",
        "        round_width = int(max(round_width, 64))\n",
        "\n",
        "    return round_width, round_height\n",
        "\n",
        "\n",
        "class controlnetRequest():\n",
        "    def __init__(self, host_url):\n",
        "        self.host_url = host_url\n",
        "\n",
        "    def send_request(self, url, body):\n",
        "        print('sending request')\n",
        "        print(body)\n",
        "        r = requests.post(url, json=body, headers={\n",
        "                          'Bypass-Tunnel-Reminder': 'please'})\n",
        "        resp = r.json()\n",
        "        return resp\n",
        "\n",
        "    def send_txt2img_request(self, input_image, module, model, **kwargs):\n",
        "        \"\"\" Send a request txt2img to the controlnet api\n",
        "        Args:\n",
        "            hint_image: the hint image\n",
        "            kwargs: the parameters of the controlnet\n",
        "                - nb_steps: the number of steps\n",
        "                - prompt: the prompt\n",
        "                - negative_prompt: the negative prompt\n",
        "                - seed: the seed\n",
        "                - subseed: the subseed\n",
        "                - subseed_strength: the subseed strength\n",
        "                - batch_size: the batch size\n",
        "                - n_iter: the number of iterations\n",
        "                - steps: the number of steps\n",
        "                - cfg_scale: the cfg scale\n",
        "                - restore_faces: true if we want to restore faces\n",
        "                - eta: the eta\n",
        "                - sampler_index: the sampler index\n",
        "                - controlnet_module: the controlnet module\n",
        "                - controlnet_model: the controlnet model\n",
        "                - controlnet_guidance: the controlnet guidance\n",
        "\n",
        "        \"\"\"\n",
        "        url = f\"{self.host_url}/controlnet/txt2img\"\n",
        "        width, height = adjust_size(input_image.shape[1], input_image.shape[0])\n",
        "\n",
        "        input_image_b64 = cv_to_b64(input_image).decode(\"utf-8\")\n",
        "\n",
        "        # get the parameters from the kwargs or use default value\n",
        "        body = {\n",
        "            \"prompt\": kwargs.get(\"prompt\", \"\"),\n",
        "            \"negative_prompt\": kwargs.get(\"negative_prompt\", \"\"),\n",
        "            \"seed\": kwargs.get(\"seed\", -1),\n",
        "            \"subseed\": kwargs.get(\"subseed\", -1),\n",
        "            \"subseed_strength\": kwargs.get(\"subseed_strength\", 0),\n",
        "            \"batch_size\": kwargs.get(\"batch_size\", 1),\n",
        "            \"n_iter\": kwargs.get(\"n_iter\", 1),\n",
        "            \"steps\": kwargs.get(\"steps\", 30),\n",
        "            \"cfg_scale\": kwargs.get(\"cfg_scale\", 7),\n",
        "            \"width\": width,\n",
        "            \"height\": height,\n",
        "            \"restore_faces\": kwargs.get(\"restore_faces\", True),\n",
        "            \"eta\": kwargs.get(\"eta\", 0),\n",
        "            \"sampler_index\": kwargs.get(\"sampler_index\", \"Euler a\"),\n",
        "            \"controlnet_input_image\": [input_image_b64],\n",
        "            \"controlnet_module\": module,\n",
        "            \"controlnet_model\": model,\n",
        "            \"controlnet_guidance\": kwargs.get(\"controlnet_guidance\", 1.0),\n",
        "            'controlnet_threshold_a': kwargs.get('controlnet_threshold_a', 100),\n",
        "            'controlnet_threshold_b': kwargs.get('controlnet_threshold_b', 100),\n",
        "            'controlnet_preprocessor_res': kwargs.get('controlnet_preprocessor_res', 64),\n",
        "        }\n",
        "        print('before send:')\n",
        "        print(body)\n",
        "\n",
        "        return self.send_request(url, body)\n",
        "\n",
        "    def send_detect_request(self, input_image, module, **kwargs):\n",
        "        \"\"\" Send a request detect to the controlnet api\n",
        "        Args:\n",
        "            input_image: the input image \n",
        "            module: the controlnet module [canny, depth, ...]\n",
        "            kwargs: the parameters of the controlnet\n",
        "                - preprocessor_res: the preprocessor resolution\n",
        "                - threshold_a: the threshold a\n",
        "                - threshold_b: the threshold b\n",
        "        \"\"\"\n",
        "        url = f\"{self.host_url}/controlnet/detect\"\n",
        "\n",
        "        hint_b64 = cv_to_b64(input_image).decode(\"utf-8\")\n",
        "\n",
        "        body = {\n",
        "            'controlnet_module': module,\n",
        "            'controlnet_preprocessor_res': kwargs.get('controlnet_preprocessor_res', 64),\n",
        "            'controlnet_input_images': [hint_b64],\n",
        "            'conytolnet_threshold_a': kwargs.get('controlnet_threshold_a', 100),\n",
        "            'controlnet_threshold_b': kwargs.get('controlnet_threshold_b', 100),\n",
        "        }\n",
        "\n",
        "        return self.send_request(url, body)\n",
        "\n",
        "\n",
        "def generate_controlnet(input_image, module, model, host_url=\"http://localhost:7861\", kwargs={}):\n",
        "\n",
        "    req = controlnetRequest(host_url)\n",
        "    resp = req.send_txt2img_request(input_image, module, model, **kwargs)\n",
        "\n",
        "    return resp['images']\n",
        "\n",
        "\n",
        "def generate_hint(input_image, module, host_url=\"http://localhost:7861\", kwargs = {}):\n",
        "    req = controlnetRequest(host_url)\n",
        "    resp = req.send_detect_request(input_image, module, **kwargs)\n",
        "    print(resp)\n",
        "    return resp['images']\n",
        "\n",
        "def write_b64_img(path, cv_image):\n",
        "    decoded_data = base64.b64decode(cv_image)\n",
        "    np_data = np.fromstring(decoded_data,np.uint8)\n",
        "    img = cv2.imdecode(np_data,cv2.IMREAD_UNCHANGED)\n",
        "    cv2.imwrite(path, img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1Pj06M7u2Ft",
        "cellView": "form",
        "outputId": "51860f1a-9658-4111-ce65-9bb5bf716e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/stable-diffusion-webui'\n",
            "/content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
            "\n",
            "\n",
            "\n",
            "Everything is ready! Click on the this link to be redirected to koll.ai. Don't close this tab!\n",
            ">>>>  https://meme.koll.ai?gpuURL=polite-hairs-make-34-90-154-50.loca.lt  <<<<\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown # 2. Run this cell and click on the link below to be redirected to the website\n",
        "#@markdown You have to wait for A1111 API to be started before starting to generate images  (logs in /content/output_webui.txt)  (~1 min)\n",
        "#@markdown * Ready when 127.0.0.1 url is displayed at the end of the file\n",
        "#@markdown * Click again on the file to refresh the output\n",
        "\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "# run localtunnel\n",
        "with open('/content/output_tunnel.txt', 'w') as f:\n",
        "    proc = subprocess.Popen(['lt', '--port', '5000'], stdout=f)\n",
        "\n",
        "\n",
        "# os.environ['COMMANDLINE_ARGS'] = \"--port 7861 --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --xformers\" \n",
        "# os.environ['COMMANDLINE_ARGS'] = \"--no-hashing --nowebui --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt {model_path} --xformers\" \n",
        "# os.environ['REQS_FILE'] = \"requirements.txt\"\n",
        "\n",
        "# with open('/content/output_webui.txt', 'w') as f:\n",
        "#     proc_automatic = subprocess.Popen(['python', '-u', 'launch.py'], stdout=f, stderr=f)\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "params = dict()\n",
        "\n",
        "API_URL  = \"\"\n",
        "BACK_URL = \"https://controle-meme-back-n7bkntouja-uc.a.run.app\"\n",
        "\n",
        "#Route to generate the hint according to processor, thresholdA and thresholdB\n",
        "@app.route('/hint/', methods=['POST'])\n",
        "def hint():\n",
        "    params = request.get_json()\n",
        "    print(params)\n",
        "    meme_url = params['controlnet_basememe_url']\n",
        "    processor_module = params['controlnet_module']\n",
        "    thresholdA = params['controlnet_threshold_a']\n",
        "    thresholdB = params['controlnet_threshold_b']\n",
        "    \n",
        "    # read the image from the url to cv2\n",
        "    base_meme = imutils.url_to_image(meme_url)   \n",
        "\n",
        "    hint = generate_hint(base_meme, processor_module, kwargs=params)\n",
        "    hint = hint[0]\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    return hint\n",
        "\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def index():\n",
        "    global params\n",
        "\n",
        "    params = request.get_json()\n",
        "    meme_url = params['controlnet_basememe_url']\n",
        "    module = params['controlnet_module']\n",
        "    model  = params['controlnet_model']\n",
        "    \n",
        "    # read the image from the url to cv2\n",
        "    base_meme = imutils.url_to_image(meme_url)    \n",
        "\n",
        "    # todo: send request to sdwebui api to get the generated image\n",
        "    try: \n",
        "        last_image = generate_controlnet(base_meme, module, model, kwargs=params)\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return \"Automatic api subprocess is not fully started yet, please try again in a minute\", 500\n",
        "      \n",
        "    last_image_b64 = last_image[0]\n",
        "    last_hint_b64 = last_image[1]\n",
        "    \n",
        "    # with open('./last_meme.jpeg', 'w') as f:\n",
        "    #   Image.open(BytesIO(base64.b64decode(last_image))).save(f, format=\"JPEG\")\n",
        "    # with open(\"./last_meme.jpeg\", \"wb\") as f:\n",
        "    #    f.write(last_image_b64)\n",
        "\n",
        "\n",
        "    write_b64_img('./last_meme.jpeg', last_image_b64)\n",
        "    write_b64_img('./last_hint.jpeg', last_hint_b64)\n",
        "\n",
        "\n",
        "\n",
        "    return last_image_b64\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/save_last/')\n",
        "def save_last():\n",
        "    global params\n",
        "\n",
        "    # last_image = Image.open('./last_meme.jpeg')\n",
        "    # buffered = BytesIO()\n",
        "    # last_image.save(buffered, format=\"JPEG\")\n",
        "    # img_str = base64.b64encode(buffered.getvalue())\n",
        "\n",
        "    last_image = cv2.imread('./last_meme.jpeg')\n",
        "    img_str = cv_to_b64(last_image)\n",
        "\n",
        "    last_hint = cv2.imread('./last_hint.jpeg')\n",
        "    hint_str = cv_to_b64(last_hint)\n",
        "\n",
        "    data = dict(\n",
        "        imageb64=img_str.decode(\"utf-8\"),\n",
        "        hintb64=hint_str.decode(\"utf-8\"),\n",
        "        **params\n",
        "    )\n",
        "    url = f'{BACK_URL}/api/save_variation/'\n",
        "    requests.post(url, json = data)\n",
        "\n",
        "    return \"ok\"\n",
        "\n",
        "\n",
        "@app.route('/generate_video/', methods=['POST'])\n",
        "def generate_video():\n",
        "    params = request.get_json()\n",
        "    \n",
        "    parent_url = params['parent_url']\n",
        "    variation_url = params['variation_url']\n",
        "\n",
        "    path_video = generate_video_ffmep(parent_url, variation_url)\n",
        "\n",
        "    return send_file(path_video)\n",
        "\n",
        "\n",
        "@app.route('/hello/')\n",
        "def hello():    \n",
        "    return \"hello\"\n",
        "\n",
        "# todo: add route to check if automatic api is started\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  with open('/content/output_tunnel.txt', 'r') as f:\n",
        "      contents = f.read()\n",
        "      API_URL = contents.split(' ')[-1]\n",
        "      protocol = API_URL.split(':')[0]\n",
        "      url = API_URL.split('/')[-1].strip()\n",
        "\n",
        "      print('\\n'*2)\n",
        "      print(f'Everything is ready! Click on the this link to be redirected to koll.ai. Don\\'t close this tab!')\n",
        "      print(f'>>>>  https://meme.koll.ai?gpuURL={url}  <<<<')\n",
        "\n",
        "from IPython.utils import capture\n",
        "\n",
        "# with capture.capture_output() as cap:\n",
        "#   app.run()\n",
        "\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}